services:
  # MongoDB
  mongodb:
    build:
      context: infrastructure/mongodb/
      dockerfile: Dockerfile
    container_name: openframe-mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: openframe
      MONGO_INITDB_ROOT_PASSWORD: password123456789
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
      - ./init/mongodb:/docker-entrypoint-initdb.d
      - mongodb_logs:/var/log/mongodb # Shared volume for logs
    networks:
      - openframe-network
    depends_on:
      - loki
    healthcheck:
      test: ["CMD", "mongosh", "--username", "openframe", "--password", "password123456789", "--eval", "db.adminCommand('ping').ok", "--quiet"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # MongoDB Exporter
  mongodb-exporter:
    image: bitnami/mongodb-exporter:latest
    container_name: openframe-mongodb-exporter
    environment: 
      MONGODB_URI: mongodb://openframe:password123456789@mongodb:27017/openframe
    ports:
      - "9216:9216"
    depends_on:
      - mongodb
      - loki
    networks:
      - openframe-network

  # Cassandra
  cassandra:
    build:
      context: infrastructure/cassandra/
      dockerfile: Dockerfile
    container_name: openframe-cassandra
    ports:
      - "9042:9042"
      - "7199:7199"
      - "9404:9404"
    volumes:
      - cassandra_data:/var/lib/cassandra
      - cassandra_logs:/var/log/cassandra # Shared volume for logs
      - ./init/cassandra:/docker-entrypoint-initdb.d
      - ./infrastructure/cassandra/jmx_exporter:/opt/jmx_exporter
      - ./monitoring/prometheus/jmx_prometheus_javaagent.jar:/opt/jmx_exporter/jmx_prometheus_javaagent.jar
    environment:
      CASSANDRA_CLUSTER_NAME: openframe_cluster
      CASSANDRA_DC: datacenter1
      CASSANDRA_START_RPC: true
      CASSANDRA_NATIVE_TRANSPORT_MAX_THREADS: 128
      CASSANDRA_NATIVE_TRANSPORT_PORT_SSL: 9142
      CASSANDRA_NATIVE_TRANSPORT_MAX_FRAME_SIZE: 256MB
      # Skip some startup checks
      CASSANDRA_SKIP_WAIT_FOR_GOSSIP_TO_SETTLE: 0
      # Reduce time it waits for other seeds
      CASSANDRA_RING_DELAY: 0
      # Skip automatic bootstrap on startup
      CASSANDRA_AUTO_BOOTSTRAP: "false"
      # Reduce the delay before starting the compaction process
      CASSANDRA_COMPACTION_THROUGHPUT_MB_PER_SEC: 0
      # Reduce initial heap size
      HEAP_NEWSIZE: 128M
      MAX_HEAP_SIZE: 512M
      # Reduce delay before accepting CQL connections
      CASSANDRA_INITIAL_TOKEN: "-9223372036854775808"
      JVM_OPTS: -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=9404:/opt/jmx_exporter/config.yml
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'select now() from system.local;' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - openframe-network
    depends_on:
      - loki

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: openframe-zookeeper
    ports:
      - "2181:2181"
      - "7070:7070"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOO_4LW_COMMANDS_WHITELIST: "*" # Allow all 4-letter commands
      ZOOKEEPER_TICK_TIME: 2000
      EXTRA_ARGS: -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=7070:/opt/jmx_exporter/config.yml
    volumes:
      - ./infrastructure/zookeeper/jmx_exporter:/opt/jmx_exporter
      - ./monitoring/prometheus/jmx_prometheus_javaagent.jar:/opt/jmx_exporter/jmx_prometheus_javaagent.jar
    networks:
      - openframe-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/commands/stat || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    depends_on:
      - loki

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: openframe-kafka
    ports:
      - "9092:9092"
      - "9308:9308"
    volumes:
      - kafka_logs:/var/log/kafka # Shared volume for logs
      - ./infrastructure/kafka/jmx_exporter:/opt/jmx_exporter
      - ./monitoring/prometheus/jmx_prometheus_javaagent.jar:/opt/jmx_exporter/jmx_prometheus_javaagent.jar
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://openframe-kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "pinot-events:1:1"
      KAFKA_OPTS: "-javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=9308:/opt/jmx_exporter/config.yml -Dzookeeper.connect.timeout.ms=60000 -Dzookeeper.session.timeout.ms=60000"
    networks: 
      - openframe-network
    depends_on:
      - loki
      - zookeeper
    healthcheck:
      test: ["CMD-SHELL", "curl localhost:9092 | grep Empty || exit 0"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Nifi
  nifi:
    container_name: openframe-nifi
    build:
      context: infrastructure/nifi/
      dockerfile: Dockerfile
    ports:
      - "8443:8443"
      - "9096:9096"
    environment:  
      NIFI_WEB_HTTPS_PORT: 8443
      NIFI_WEB_HTTP_HOST: 0.0.0.0
      SINGLE_USER_CREDENTIALS_USERNAME: openframe
      SINGLE_USER_CREDENTIALS_PASSWORD: password123456789
    volumes:
      - nifi_content:/opt/nifi/nifi-current/content_repository
      - nifi_database:/opt/nifi/nifi-current/database_repository
      - nifi_flowfile:/opt/nifi/nifi-current/flowfile_repository
      - nifi_provenance:/opt/nifi/nifi-current/provenance_repository
      - nifi_state:/opt/nifi/nifi-current/state
      - nifi_logs:/opt/nifi/nifi-current/logs
    networks:
      - openframe-network
    depends_on:
      - loki

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: openframe-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    networks:
      - openframe-network
    depends_on:
      - loki
    
  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: openframe-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=openframe
      - GF_SECURITY_ADMIN_PASSWORD=password123456789
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards
      - grafana_data:/var/lib/grafana
    networks:
      - openframe-network
    depends_on:
      - loki
      - prometheus

  # Kafka UI
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: openframe-kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    networks:
      - openframe-network
    depends_on:
      - loki
      - kafka

  # Mongo Express
  mongo-express:
    image: mongo-express:latest
    container_name: openframe-mongo-express
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: openframe
      ME_CONFIG_MONGODB_ADMINPASSWORD: password123456789
      ME_CONFIG_MONGODB_URL: mongodb://openframe:password123456789@mongodb:27017/
    networks:
      - openframe-network
    depends_on:
      - loki
      - mongodb

  # Loki
  loki:
    image: grafana/loki:latest
    container_name: openframe-loki
    ports:
      - "3100:3100"
    command:
      - "-config.file=/etc/loki/local-config.yaml"
      - "-config.expand-env=true"
      - "-validation.allow-structured-metadata=false"
    volumes:
      - ./monitoring/loki:/etc/loki
      - loki_data:/loki
    networks:
      openframe-network:
        aliases:
          - loki
    healthcheck:
      test: ["CMD-SHELL", "wget -q --try-connect-timeout=1 -O - http://localhost:3100/ready || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  pinot-controller:
    image: apachepinot/pinot:latest
    container_name: openframe-pinot-controller
    command: StartController -configFileName /opt/pinot/config/pinot.conf
    ports:
      - "9000:9000"
      - "9011:9011"  # JMX Exporter metrics
    volumes:
      - ./infrastructure/pinot/config:/opt/pinot/config
      - pinot_controller_data:/opt/pinot/data
      - ./infrastructure/pinot/jmx_exporter:/opt/jmx_exporter
      - ./monitoring/prometheus/jmx_prometheus_javaagent.jar:/opt/jmx_exporter/jmx_prometheus_javaagent.jar
    environment:
      JAVA_OPTS: >
        -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=9011:/opt/jmx_exporter/config.yml
        -Xmx1G -Xms1G -XX:+UseG1GC -XX:MaxGCPauseMillis=200
    networks:
      - openframe-network
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  pinot-broker:
    image: apachepinot/pinot:latest
    container_name: openframe-pinot-broker
    command: StartBroker -clusterName openframe-pinot -zkAddress openframe-zookeeper:2181 -configFileName /opt/pinot/config/pinot.conf
    ports:
      - "8099:8099"
      - "9012:9012"  # JMX Exporter metrics
    volumes:
      - ./infrastructure/pinot/config:/opt/pinot/config
      - pinot_broker_data:/opt/pinot/data
      - ./infrastructure/pinot/jmx_exporter:/opt/jmx_exporter
      - ./monitoring/prometheus/jmx_prometheus_javaagent.jar:/opt/jmx_exporter/jmx_prometheus_javaagent.jar
    environment:
      JAVA_OPTS: >
        -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=9012:/opt/jmx_exporter/config.yml
        -Xmx2G -Xms2G -XX:+UseG1GC -XX:MaxGCPauseMillis=200
    networks:
      - openframe-network
    depends_on:
      pinot-controller:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8099/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  pinot-server:
    image: apachepinot/pinot:latest
    container_name: openframe-pinot-server
    command: StartServer -clusterName openframe-pinot -zkAddress openframe-zookeeper:2181 -configFileName /opt/pinot/config/pinot.conf
    ports:
      - "8097:8097"  # Admin port
      - "9013:9013"  # JMX Exporter metrics
    volumes:
      - ./infrastructure/pinot/config:/opt/pinot/config
      - pinot_server_data:/opt/pinot/data
      - ./infrastructure/pinot/jmx_exporter:/opt/jmx_exporter
      - ./monitoring/prometheus/jmx_prometheus_javaagent.jar:/opt/jmx_exporter/jmx_prometheus_javaagent.jar
    environment:
      JAVA_OPTS: >
        -javaagent:/opt/jmx_exporter/jmx_prometheus_javaagent.jar=9013:/opt/jmx_exporter/config.yml
        -Xmx2G -Xms2G -XX:+UseG1GC -XX:MaxGCPauseMillis=200
    networks:
      - openframe-network
    depends_on:
      pinot-controller:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8097/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  promtail:
    image: grafana/promtail:latest
    container_name: openframe-promtail
    volumes:
      - ./monitoring/promtail:/etc/promtail
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command:
      - -config.file=/etc/promtail/config.yml
      - -config.expand-env=true
    depends_on:
      - loki
    networks:
      - openframe-network
    restart: unless-stopped

networks:
  openframe-network:
    name: openframe-network
    driver: bridge

volumes:
  loki_data:
  mongodb_data:
  mongodb_logs: # MongoDB logs
  cassandra_data:
  cassandra_logs: # Cassandra logs
  kafka_logs: # Kafka logs
  nifi_content:
  nifi_database:
  nifi_flowfile:
  nifi_provenance:
  nifi_state:
  nifi_logs: # Nifi logs
  prometheus_data:
  grafana_data:
  pinot_broker_data:
  pinot_server_data:
  pinot_controller_data: